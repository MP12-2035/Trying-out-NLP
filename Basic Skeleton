# Install dependencies:
# pip install transformers datasets torch

import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments

# ---- Step 1: Load pre-trained GPT2 ----
model_name = "distilgpt2"  # lighter GPT-2
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)

# ---- Step 2: Prepare dataset ----
def load_dataset(file_path, tokenizer, block_size=128):
    from torch.utils.data import Dataset
    class ChatDataset(Dataset):
        def __init__(self, text_file):
            with open(text_file, 'r', encoding='utf-8') as f:
                self.lines = f.read().splitlines()
            self.examples = []
            for line in self.lines:
                tokens = tokenizer.encode(line, add_special_tokens=True, max_length=block_size, truncation=True)
                self.examples.append(torch.tensor(tokens))
        def __len__(self):
            return len(self.examples)
        def __getitem__(self, i):
            return self.examples[i]
    return ChatDataset(file_path)

dataset = load_dataset("your_chat.txt", tokenizer)

data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)

# ---- Step 3: Training setup ----
training_args = TrainingArguments(
    output_dir="./chatbot_model",
    overwrite_output_dir=True,
    num_train_epochs=3,
    per_device_train_batch_size=2,
    save_steps=200,
    save_total_limit=2,
    logging_steps=50
)

trainer = Trainer(
    model=model,
    args=training_args,
    data_collator=data_collator,
    train_dataset=dataset
)

# ---- Step 4: Train ----
trainer.train()

# ---- Step 5: Generate responses ----
def chat(prompt, max_length=50):
    inputs = tokenizer.encode(prompt, return_tensors="pt")
    outputs = model.generate(inputs, max_length=max_length, pad_token_id=tokenizer.eos_token_id)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

while True:
    user_input = input("You: ")
    if user_input.lower() in ["exit", "quit"]:
        break
    response = chat(user_input)
    print("Bot:", response)
